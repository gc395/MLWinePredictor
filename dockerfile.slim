# Use a minimal Python base
FROM python:3.9-slim

# Install dependencies for Java and other utilities
RUN apt-get update && apt-get install -y openjdk-11-jdk wget curl unzip && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Set environment variables for Spark
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV SPARK_HOME=/opt/spark
ENV PATH=$SPARK_HOME/bin:$PATH

# Download and install Spark
RUN wget https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz && \
    tar -xzf spark-3.5.0-bin-hadoop3.tgz && \
    mv spark-3.5.0-bin-hadoop3 /opt/spark && \
    rm spark-3.5.0-bin-hadoop3.tgz

# Install Python dependencies
RUN pip install --no-cache-dir pyspark pandas scikit-learn

# Set working directory
WORKDIR /app

# Copy your project files into the image
COPY train_model.py predict_model.py TrainingDataset.csv ValidationDataset.csv ./

# Default command for the container
CMD ["spark-submit", "train_model.py", "TrainingDataset.csv", "ValidationDataset.csv"]
